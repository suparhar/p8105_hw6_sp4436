---
title: "p8105_hw6_sp4436"
author: "Sukhman Parhar"
date: "2025-12-03"
output: github_document
---

```{r Load Packages, message = FALSE, warning = FALSE}
library(tidyverse)
library(readxl)
library(haven)
library(readr) 
library(p8105.datasets)
library(ggridges)
library(dplyr)
library(janitor)
library(patchwork)
library(broom)
library(modelr)

```

## Problem 1

```{r Load in the data}
homicide_df =
  read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv") |> 
  janitor::clean_names() |>
  mutate(
    city_state = str_c(city, ", ", state)
  ) |>
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black")
  ) |>
  mutate(
    victim_age = as.numeric(victim_age),
    case_status = ifelse(disposition == "Closed by arrest", 1, 0)
  ) |>
  filter(!is.na(victim_age))
```

```{r Baltimore GLM}
baltimore_results =
  homicide_df |> 
  filter(city_state == "Baltimore, MD") |> 
  glm(
    case_status ~ victim_age + victim_sex + victim_race,
    family = binomial(),
    data = _
  ) |> 
  broom::tidy(conf.int = TRUE) |> 
  mutate(
    OR = exp(estimate),
    OR_CI_lower = exp(conf.low),
    OR_CI_upper = exp(conf.high)
  ) |>
  filter(term == "victim_sexMale") |> 
  select(term, log_OR = estimate, OR, p.value, OR_CI_lower, OR_CI_upper)

baltimore_results |> knitr::kable(digits = 3)
```

The adjusted odds ratio for solving homicides comparing male victims to female victims in Baltimore is 0.426 (95% CI: 0.324, 0.558), controlling for victim age and race.

Because the confidence interval does not include 1, this association is statistically significant. This OR indicates that homicides involving male victims have approximately 57% lower odds of being solved than homicides involving female victims, after accounting for age and race. A range of reasonable estimates for the true odds ratio comparing the probability of solving homicides involving male victims versus female victims, consistent with our data and model assumptions, is between 0.324 and 0.558.

```{r All City OR and CI}
city_or_results =
  homicide_df |> 
  nest(data = -city_state) |> 
  mutate(
    fit = map(
      data,
      ~ glm(case_status ~ victim_age + victim_sex + victim_race,
            family = binomial(), data = .x)
    ),
    tidy_fit = map(fit, ~ broom::tidy(.x, conf.int = TRUE))
  ) |>
  unnest(tidy_fit) |>
  filter(term == "victim_sexMale") |>
  mutate(
    OR = exp(estimate),
    OR_CI_lower = exp(conf.low),
    OR_CI_upper = exp(conf.high)
  ) |>
  select(city_state, OR, OR_CI_lower, OR_CI_upper)

city_or_results |> 
  knitr::kable(digits = 3)

```

```{r All City OR Plot}
## Plot of city-specific ORs and 95% CIs (Male vs Female victims)

city_or_results |>
  arrange(OR) |>
  mutate(city_state = factor(city_state, levels = city_state)) |>
  ggplot(aes(x = OR, y = city_state)) +
  geom_point() +
  geom_errorbarh(aes(xmin = OR_CI_lower, xmax = OR_CI_upper), width = 0.15) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  labs(
    title = "Adjusted Odds of Solving Homicides: Male vs Female Victims",
    x = "Odds ratio (Male vs Female victims)",
    y = "City"
  ) +
  theme_minimal()
```

This plot shows substantial variation across cities in the adjusted odds of solving homicides involving male victims compared to female victims after controlling for victim age and race. Several cities (Albuquerque, NM; Stockton, CA; and Fresno, CA) have the highest estimated odds ratios, suggesting that male-victim homicides are more likely to be solved than female-victim homicides. However, these estimates have very wide confidence intervals that include the null value of 1, meaning there is no statistically significant evidence of a difference in solve probability in these cities.

At the lower end, cities such as New York, NY; Baton Rouge, LA; and Omaha, NE show the lowest odds ratios, indicating that homicides involving male victims are less likely to be solved than those involving female victims. In these cities, the confidence intervals lie below 1, providing statistically significant evidence for lower solve rates among male-victim cases. The CIs for these cities overlap so wecannot see which city has the lowest OR.

The plot shows that many cities show lower solve rates for male victims, the precision varies widely, and statistical significance is mainly seen among cities with larger sample sizes and narrower confidence intervals.

## Problem 2

```{r Import Data}
set.seed(1)
data("weather_df")

bootstrap_results =
  weather_df |>
  modelr::bootstrap(n = 5000) |>
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df)),
    results_glance = map(models, broom::glance),
    results_tidy = map(models, broom::tidy)
  ) |>
  select(-strap, -models) |>
  unnest(results_glance) |>
  select(.id, r.squared, results_tidy) |>
  unnest(results_tidy) |>
  select(.id, r.squared, term, estimate) |>
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) |>
  mutate(
    beta_ratio = tmin / prcp   # β̂₁ / β̂₂
  )
```

```{r Plots}
p1 = bootstrap_results |>
  ggplot(aes(x = r.squared)) +
  geom_density(fill = "blue", alpha = 0.5) +
  labs(title = "Bootstrap Distribution of R²", x = "R²")

p2 = bootstrap_results |>
  ggplot(aes(x = beta_ratio)) +
  geom_density(fill = "red", alpha = 0.5) +
  labs(title = "Distribution of β₁ / β₂", x = "Coefficient Ratio")

p1 + p2
```

```{r CI Results}
ci_results =
  bootstrap_results |>
  summarize(
    r_squared_low = quantile(r.squared, 0.025),
    r_squared_high = quantile(r.squared, 0.975),
    beta_ratio_low = quantile(beta_ratio, 0.025),
    beta_ratio_high = quantile(beta_ratio, 0.975)
  )

knitr::kable(ci_results, digits = 4)
```

## Problem 3

```{r Load in the Data and Clean}
bw_df = read_csv("birthweight.csv") |> 
  janitor::clean_names() |> 
  mutate(
    babysex = factor(babysex, levels = c(1, 2),
                     labels = c("Male", "Female")),
    
    frace = factor(frace, 
                   levels = c(1, 2, 3, 4, 8, 9),
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")),
    
    mrace = factor(mrace,
                   levels = c(1, 2, 3, 4, 8),
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    
    malform = factor(malform, 
                     levels = c(0, 1),
                     labels = c("Absent", "Present"))
  )
summary(is.na(bw_df))
```

The following model focuses on maternal risk factors and pregnancy characteristics that are associated with infant birthweight. The following predictors are hypothesized to drive birthweight:

Gestational age (gaweeks)

Maternal age at delivery (momage)

Pre-pregnancy BMI (ppbmi)

Weight gain during pregnancy (wtgain)

Smoking during pregnancy (smoken)

Maternal race (mrace)

Family income (fincome)

Several available variables were evaluated for inclusion but excluded. Variables such as pnumlbw (previous low birthweight babies) and parity showed extremely limited variability in the dataset. They provided no additional explanatory power. Infant physical measurements (blength, bhead) were not included because they capture fetal growth outputs rather than maternal predictors.

```{r Model and Plot for BW}
bw_mod_main =
  lm(
    bwt ~ gaweeks + momage + ppbmi + wtgain + smoken + mrace + fincome,
    data = bw_df
  )

summary(bw_mod_main)

bw_df |> 
  add_predictions(bw_mod_main) |> 
  add_residuals(bw_mod_main) |> 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(
    title = "Residuals vs Fitted Values (Model 1)",
    x = "Fitted Values (Predicted Birthweight)",
    y = "Residuals"
  ) +
  theme_minimal()
```

```{r Fit Comparison Models for BW}
bw_mod_simple =
  lm(bwt ~ blength + gaweeks, data = bw_df)

bw_mod_interaction =
  lm(bwt ~ bhead * blength * gaweeks, data = bw_df)
```

```{r RMSE and Plot}
set.seed(1)

#Generate CV splits and convert to tibbles
cv_df =
  crossv_mc(bw_df, n = 100) |>
  mutate(
    train = map(train, as_tibble),
    test  = map(test,  as_tibble)
  )

#Fit all three models on each training fold
cv_df =
  cv_df |>
  mutate(
    mod_main   = map(train, \(df) lm(bwt ~ gaweeks + momage + ppbmi + wtgain + smoken + mrace + fincome, data = df)),
    mod_simple = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    mod_inter  = map(train, \(df) lm(bwt ~ bhead * blength * gaweeks, data = df))
  )

#Compute RMSE
cv_df =
  cv_df |>
  mutate(
    rmse_main   = map2_dbl(mod_main,   test, modelr::rmse),
    rmse_simple = map2_dbl(mod_simple, test, modelr::rmse),
    rmse_inter  = map2_dbl(mod_inter,  test, modelr::rmse)
  )

#Pivot into long format for plotting
cv_long =
  cv_df |>
  select(starts_with("rmse")) |>
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) |>
  mutate(
    model = fct_inorder(recode(model,
                               main   = "Main model",
                               simple = "Length + GA",
                               inter  = "3-way interaction"))
  )

#Violin plot 
cv_long |>
  ggplot(aes(x = model, y = rmse, fill = model)) +
  geom_violin(alpha = 0.7, color = "black") +
  scale_fill_viridis_d() +
  labs(
    title = "Model Comparison via Cross-Validation",
    x = "Model",
    y = "Root Mean Squared Error (RMSE)"
  ) +
  theme_minimal()
```

The cross-validated RMSE plot shows clear differences in predictive performance across the three models. The maternal-factor model (My Model) has the highest RMSE values and the largest spread. This means that it performs the worst in terms of predicting birthweight.

The Length + Gestational Age model (Model 2) performs better, with lower RMSE values. Birth length and gestational age are direct markers of fetal growth, so they provide much stronger predictive information than maternal factors alone.

The full interaction model (Model 3), which incorporates head circumference, length, sex, and all lower-order interactions, achieves the lowest RMSE overall.

Overall, the my model is not optimal for prediction. The other two models are have better predictive accuracy mainly the model including the interaction term.